{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e661de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset file (e.g., labels.csv)\n",
    "df = kagglehub.dataset_load(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"vasukipatel/face-recognition-dataset\",\n",
    "    \"labels.csv\",  # Adjust this to the actual CSV or data file\n",
    "    pandas_kwargs={\"usecols\": [\"filename\", \"label\"]}  # Adjust if needed\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path if needed\n",
    "dataset_dir = \"/kaggle/input/face-recognition-dataset\"\n",
    "image_size = (100, 100)\n",
    "\n",
    "def load_images(df, base_dir, image_size=(100, 100)):\n",
    "    images, labels = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(base_dir, row['filename'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)\n",
    "            images.append(img)\n",
    "            labels.append(row['label'])\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X, y = load_images(df, dataset_dir, image_size)\n",
    "X = X.astype('float32') / 255.0\n",
    "print(f\"Loaded {len(X)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)  # Change index if you have multiple webcams\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face_resized = cv2.resize(face, (100, 100)) / 255.0\n",
    "        face_input = np.expand_dims(face_resized, axis=0)\n",
    "\n",
    "        pred = model.predict(face_input)[0][0]\n",
    "        label = \"Person\" if pred > 0.5 else \"Other\"\n",
    "        color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, f\"{label} ({pred:.2f})\", (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
